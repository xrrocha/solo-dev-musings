---
layout: default
title: "VI. Forced Articulation"
nav_exclude: true
---

# VI. Forced Articulation

![Dialogue](../img/06-dialogue.webp)

Having rejected the strawman (AI reduces labor costs, therefore solves documentation), we can ask what AI collaboration *actually* changes about Naur's challenge.

---

## The Interlocutor Effect

When a programmer works alone, much reasoning remains implicit. The programmer knows why a decision was made but never articulates it because there is no interlocutor.

AI collaboration introduces a persistent interlocutor. To direct an AI assistant effectively, the programmer must articulate:

- Intentions
- Constraints
- Rationales
- Criteria for success

This articulation is captured‚Äîin transcripts, in prompts, in session records‚Äîand becomes material for theory reconstruction.

---

## Shifting the Boundary

This does not solve the tacit knowledge problem. Some knowledge remains beyond articulation‚Äîthe Stradivarius problem persists.

But it shifts the boundary, making explicit what might otherwise have remained implicit. The interlocutor forces thoughts into words. Those words, once spoken, can be preserved.

The difference is not that AI extracts tacit knowledge (it cannot). The difference is that explaining to AI makes *articulable* knowledge actually *articulated*.

---

## The Asymmetry

There is an asymmetry here that matters: the human retains theory between sessions; the AI forgets. This creates pressure to document not for the AI's benefit but for the human's future self‚Äîand for successors.

The AI is not the repository of theory. It is the occasion for articulating theory.

---

[‚Üê Previous](05-why-technical-docs-fail.md) | [Index](index.md) | [Next ‚Üí](07-dialogue-preservation.md)

---

üè† [Solo Dev Musings](../../README.md)
